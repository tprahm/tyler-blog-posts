{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from delta.tables import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import date_format\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import StructType, StructField, DataType, BooleanType, NumericType, TimestampType, IntegerType, DecimalType, StringType, LongType, DateType, FloatType\n",
    "from botocore.client import Config\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import groupby\n",
    "from matplotlib.ticker import StrMethodFormatter, PercentFormatter\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Modify API Key Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMBERDATA_API_KEY = \"INSERT_YOUR_AMBERDATA_API_KEY_HERE\"\n",
    "GVOL_API_KEY = \"INSERT_YOUR_AD_DERIVATIVES_API_KEY_HERE\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import OHLCV Data From Amberdata API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define start and end dates\n",
    "start_date = datetime.strptime(\"2022-01-01\", \"%Y-%m-%d\")\n",
    "end_date = datetime.strptime(\"2023-08-31\", \"%Y-%m-%d\")\n",
    "\n",
    "# Initialize empty DataFrame\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "# Create date ranges\n",
    "date_ranges = []\n",
    "while start_date < end_date:\n",
    "    new_end_date = start_date + timedelta(days=30)\n",
    "    date_ranges.append((start_date, new_end_date))\n",
    "    start_date = new_end_date\n",
    "\n",
    "# Loop through date ranges to get data\n",
    "for start, end in date_ranges:\n",
    "    url = f\"https://web3api.io/api/v2/market/spot/ohlcv/exchange/bitfinex/historical?pair=usdc_usdt&timeInterval=days&startDate={start.strftime('%Y-%m-%dT%H:%M:%S')}&endDate={end.strftime('%Y-%m-%dT%H:%M:%S')}\"\n",
    "    \n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"x-api-key\": AMBERDATA_API_KEY\n",
    "    }\n",
    "    \n",
    "    # Make the API request\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    # Parse the JSON data into a Python dictionary\n",
    "    data = response.json()\n",
    "    \n",
    "    # Get the relevant data for 'usdc_usdt' pair\n",
    "    usdc_usdt_data = data['payload']['data']['usdc_usdt']\n",
    "    \n",
    "    # Get the column names from metadata\n",
    "    columns = data['payload']['metadata']['columns']\n",
    "    \n",
    "    # Create a Pandas DataFrame with the data and column names\n",
    "    df = pd.DataFrame(usdc_usdt_data, columns=columns)\n",
    "    \n",
    "    # Convert 'timestamp' to datetime format (assuming the timestamp is in milliseconds)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "    \n",
    "    # Set 'timestamp' as the DataFrame's index\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    \n",
    "    # Append to final DataFrame\n",
    "    final_df = pd.concat([final_df, df])\n",
    "\n",
    "# Display the final DataFrame\n",
    "final_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Close Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Define Amberdata color theme\n",
    "AD_COLORS_1 = ['#1c3664', '#89bed8', '#f16623']\n",
    "\n",
    "# Create a single subplot (1 row, 1 column)\n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "\n",
    "# Line plot of close prices\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=final_df.index,\n",
    "    y=final_df['close'],\n",
    "    mode='lines',\n",
    "    name='Close',\n",
    "    line=dict(color=AD_COLORS_1[0])  # Set line color\n",
    "))\n",
    "\n",
    "# Update layout to match the theme\n",
    "fig.update_layout(\n",
    "    title='USDC/USDT Close Prices Over Time (Bitfinex)',\n",
    "    yaxis_title=\"Close\",\n",
    "    template='plotly_white',\n",
    "    height=600,\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "# Remove x-axis label\n",
    "fig.update_layout(xaxis_title=None)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Close Prices vs. Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a two-row subplot (2 rows, 1 column) with custom height ratios\n",
    "fig = make_subplots(rows=2, cols=1, shared_xaxes=True, subplot_titles=(\"Close Prices\", \"Volume\"), vertical_spacing=0.1, row_heights=[0.7, 0.3])\n",
    "\n",
    "# Line plot of close prices on the first subplot\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=final_df.index,\n",
    "        y=final_df['close'],\n",
    "        mode='lines',\n",
    "        name='Close',\n",
    "        line=dict(color=AD_COLORS_1[0])  # Set line color\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Bar plot of volume on the second subplot\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=final_df.index,\n",
    "        y=final_df['volume'],\n",
    "        name='Volume',\n",
    "        marker=dict(color=AD_COLORS_1[1])  # Set bar color\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Update layout to match the theme\n",
    "fig.update_layout(\n",
    "    title='USDC/USDT Close Prices and Volume Over Time (Bitfinex)',\n",
    "    template='plotly_white',\n",
    "    height=800,\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "# Update y-axis labels\n",
    "fig.update_yaxes(title_text=\"Close Price\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Volume\", row=2, col=1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Bid-Ask Spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window specification for timestamp\n",
    "timestampWindow = Window.partitionBy(\"exchangeTimestamp\")\n",
    "\n",
    "# Window specification for bid prices\n",
    "bid_window = Window.partitionBy('exchangeTimestamp')\\\n",
    "        .orderBy(f.desc('bid_price'))\\\n",
    "        .rowsBetween(Window.unboundedPreceding, 0)\n",
    "\n",
    "# Window specification for ask prices\n",
    "ask_window = Window.partitionBy('exchangeTimestamp')\\\n",
    "        .orderBy(f.asc('ask_price'))\\\n",
    "        .rowsBetween(Window.unboundedPreceding, 0)\n",
    "\n",
    "# Convert exchangeTimestamp to datetime format\n",
    "bid_book = bid_book.withColumn(\"exchangeTimestamp\", f.from_unixtime(col(\"exchangeTimestamp\") / 1000).cast(\"timestamp\"))\n",
    "ask_book = ask_book.withColumn(\"exchangeTimestamp\", f.from_unixtime(col(\"exchangeTimestamp\") / 1000).cast(\"timestamp\"))\n",
    "\n",
    "# Get maximum bid price and minimum ask price for each exchangeTimestamp\n",
    "bid_book = bid_book\\\n",
    "        .withColumn(\"max_bid\", f.max(\"bid_price\").over(timestampWindow))\n",
    "\n",
    "ask_book = ask_book\\\n",
    "        .withColumn(\"min_ask\", f.min(\"ask_price\").over(timestampWindow))\n",
    "\n",
    "# Join bid_book and ask_book on exchangeTimestamp\n",
    "df = bid_book.join(ask_book, on='exchangeTimestamp', how='inner')\n",
    "\n",
    "# Calculate bid-ask spread for each exchangeTimestamp\n",
    "df = df.withColumn(\"bid_ask_spread\", df.min_ask - df.max_bid)\n",
    "\n",
    "# Group by exchangeTimestamp to get a single bid-ask spread per timestamp\n",
    "df = df.groupby(\"exchangeTimestamp\")\\\n",
    "            .agg(f.first(\"bid_ask_spread\", ignorenulls=True).alias(\"bid_ask_spread\"))\n",
    "\n",
    "# Convert the Spark DataFrame to a Pandas DataFrame\n",
    "df = df.toPandas()\n",
    "\n",
    "# Set 'timestamp' as the DataFrame's index\n",
    "df.set_index('exchangeTimestamp', inplace=True)\n",
    "df.sort_index(inplace=True)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Daily Aggregated Bid-Ask Spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "# Resample to daily frequency, taking the mean\n",
    "df_daily = df['bid_ask_spread'].resample('D').mean()\n",
    "\n",
    "# Create a two-row subplot (2 rows, 1 column)\n",
    "fig = make_subplots(rows=2, cols=1, shared_xaxes=True, subplot_titles=(\"Close Prices\", \"Daily Mean Bid-Ask Spread\"), vertical_spacing=0.1)\n",
    "\n",
    "# Line plot of close prices on the first subplot\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=final_df.index,\n",
    "        y=final_df['close'],\n",
    "        mode='lines',\n",
    "        name='Close',\n",
    "        line=dict(color=AD_COLORS_1[0])\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Bar plot of daily mean bid-ask spread on the second subplot\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=df_daily.index,\n",
    "        y=df_daily,\n",
    "        name='Daily Mean Bid-Ask Spread',\n",
    "        marker=dict(color=AD_COLORS_1[1])\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Update layout to match the theme\n",
    "fig.update_layout(\n",
    "    title='USDC/USDT Close Prices and Daily Mean Bid-Ask Spread Over Time',\n",
    "    template='plotly_white',\n",
    "    height=800,\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "# Update y-axis labels\n",
    "fig.update_yaxes(title_text=\"Close Price\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Daily Mean Bid-Ask Spread\", row=2, col=1)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Orderbook Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    DeltaTable\n",
    "    .forPath(spark, 's3://amberdata-marketdata-deltalake/spot/order-book-snapshots/').toDF()\n",
    "    .where('year = \"2023\" \\\n",
    "            AND month = \"03\"\\\n",
    "            AND day IN (\"10\", \"11\", \"12\")\\\n",
    "            AND pair = \"usdc_usdt\"')\n",
    "    .select(f.explode('orderBookSides')).select(\"col.exchangeTimestamp\", \"col.isBid\", f.explode('col.data'))\n",
    ").cache()\n",
    "\n",
    "prices = (\n",
    "    DeltaTable\n",
    "    .forPath(spark, 's3://amberdata-marketdata-deltalake/spot/order-book-snapshots/').toDF()\n",
    "    .where('year = \"2023\" \\\n",
    "            AND month = \"03\"\\\n",
    "            AND day IN (\"10\", \"11\", \"12\")\\\n",
    "            AND exchange = \"bitfinex\"\\\n",
    "            AND pair = \"usdc_usdt\"')\n",
    "    .select(f.explode('orderBookSides')).select(\"col.exchangeTimestamp\", \"col.isBid\", f.explode('col.data'))\n",
    ").cache()\n",
    "\n",
    "# Enable arrow for faster Pandas conversion\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "\n",
    "# Convert to Pandas DataFrames\n",
    "df = df.toPandas()\n",
    "prices = prices.toPandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orderbook Heatmap Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['exchangeTimestamp'] = pd.to_datetime(df['exchangeTimestamp'], unit='ms')\n",
    "df['exchangeTimestamp'] = df['exchangeTimestamp'].dt.round('min')\n",
    "\n",
    "df = df.assign(price=lambda x: [val[0] for val in x['col'].values],\n",
    "               quantity=lambda x: [val[1] for val in x['col'].values])\n",
    "\n",
    "df = df.drop(['col'], axis=1)\n",
    "df.rename(columns={'exchangeTimestamp':'timestamp'}, inplace=True)\n",
    "\n",
    "bid_book = df[df['isBid']==True]\n",
    "ask_book = df[df['isBid']==False]\n",
    "\n",
    "ask_book = ask_book.sort_values(by='timestamp')\n",
    "bid_book = bid_book.sort_values(by='timestamp')\n",
    "\n",
    "prices['exchangeTimestamp'] = pd.to_datetime(prices['exchangeTimestamp'], unit='ms')\n",
    "prices['exchangeTimestamp'] = prices['exchangeTimestamp'].dt.round('min')\n",
    "\n",
    "prices = prices.assign(price=lambda x: [val[0] for val in x['col'].values],\n",
    "               quantity=lambda x: [val[1] for val in x['col'].values])\n",
    "\n",
    "prices = prices.drop(['col'], axis=1)\n",
    "prices.rename(columns={'exchangeTimestamp':'timestamp'}, inplace=True)\n",
    "\n",
    "bid_book_prices = prices[prices['isBid']==True]\n",
    "ask_book_prices = prices[prices['isBid']==False]\n",
    "\n",
    "ask_book_prices = ask_book_prices.sort_values(by='timestamp')\n",
    "bid_book_prices = bid_book_prices.sort_values(by='timestamp')\n",
    "\n",
    "lowest_ask_group = ask_book_prices.groupby('timestamp').agg({'price': 'min'})\n",
    "lowest_ask = lowest_ask_group.rename(columns={'price': 'lowest_ask'})\n",
    "\n",
    "highest_bid_group = bid_book_prices.groupby('timestamp').agg({'price': 'max'})\n",
    "highest_bid = highest_bid_group.rename(columns={'price': 'highest_bid'})\n",
    "\n",
    "prices = pd.merge(left=lowest_ask, right=highest_bid, on='timestamp')\n",
    "prices['mid_price'] = (prices['lowest_ask'] + prices['highest_bid']) / 2\n",
    "\n",
    "prices = prices.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rounded_order_book_heatmap(ask_book,\n",
    "                       bid_book,\n",
    "                       min_price = 1500,\n",
    "                       max_price = 1700,\n",
    "                       rounding_factor=1,\n",
    "                       startDate = '2023-02-24 0:00:00',\n",
    "                       endDate = '2023-02-24 1:00:00',\n",
    "                       title='Order Book Heatmap'\n",
    "                      ):\n",
    "    \n",
    "    ask_book = ask_book.copy()\n",
    "    bid_book = bid_book.copy()\n",
    "    \n",
    "    ask_book['price'] = np.floor(ask_book['price'] / rounding_factor) * rounding_factor\n",
    "\n",
    "    # Group the data by timestamp and price\n",
    "    ask_book = ask_book.groupby(['timestamp', 'price'])\n",
    "\n",
    "    # Aggregate the sum of the quantity\n",
    "    ask_book = ask_book.agg({'quantity': 'sum'})\n",
    "\n",
    "    # Reset the index\n",
    "    ask_book = ask_book.reset_index()\n",
    "\n",
    "    bid_book['price'] = np.ceil(bid_book['price'] / rounding_factor) * rounding_factor\n",
    "\n",
    "    # Group the data by timestamp and price\n",
    "    bid_book = bid_book.groupby(['timestamp', 'price'])\n",
    "\n",
    "    # Aggregate the sum of the quantity\n",
    "    bid_book = bid_book.agg({'quantity': 'sum'})\n",
    "\n",
    "    # Reset the index\n",
    "    bid_book = bid_book.reset_index()\n",
    "\n",
    "    orderbook = ask_book.append(bid_book)\n",
    "\n",
    "    # Group the data by timestamp and price\n",
    "    orderbook = orderbook.groupby(['timestamp', 'price'])\n",
    "\n",
    "    # Aggregate the sum of the quantity\n",
    "    orderbook = orderbook.agg({'quantity': 'sum'})\n",
    "\n",
    "    # Reset the index\n",
    "    orderbook = orderbook.reset_index()\n",
    "\n",
    "    # Create orderbook copies\n",
    "    orderbook_trimmed = orderbook.copy()\n",
    "    prices_trimmed = prices.copy()\n",
    "    \n",
    "    # Convert the timestamps to datetime objects\n",
    "    startDate = pd.to_datetime(startDate)\n",
    "    endDate = pd.to_datetime(endDate)\n",
    "\n",
    "    # Filter the dataframe to keep only the rows within the desired time range\n",
    "    orderbook_trimmed = orderbook_trimmed[(orderbook_trimmed['timestamp'] >= startDate) & (orderbook_trimmed['timestamp'] <= endDate)]\n",
    "    prices_trimmed = prices_trimmed[(prices_trimmed['timestamp'] >= startDate) & (prices_trimmed['timestamp'] <= endDate)]\n",
    "    \n",
    "    # Remove the orderbook top percentage of rows from the max\n",
    "    orderbook_trimmed = orderbook_trimmed[orderbook_trimmed['price'] <= max_price]\n",
    "    \n",
    "    # Remove the orderbook bottom percentage of rows from the min \n",
    "    orderbook_trimmed = orderbook_trimmed[orderbook_trimmed['price'] >= min_price]\n",
    "    \n",
    "    # Create a pivot table for orderbook with the columns reversed\n",
    "    book_pivot = orderbook_trimmed.pivot(index='timestamp', columns='price', values='quantity')\n",
    "\n",
    "    book_pivot.index = pd.to_datetime(book_pivot.index)\n",
    "    book_pivot.index = book_pivot.index.strftime('%H:%M:%S')\n",
    "\n",
    "    book_pivot = book_pivot.T\n",
    "    book_pivot = book_pivot.sort_index(ascending=False)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12,6), dpi=1000)\n",
    "    sns.heatmap(book_pivot, cmap= sns.color_palette('rocket', as_cmap=True), ax=ax, cbar_kws={'label': 'USDC/USDT Limit Order Quantity'})\n",
    "    ax.set_facecolor(\"black\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('3/11/2023 | Datetime (UTC)', labelpad=20)\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(book_pivot.columns, prices_trimmed['mid_price'], color='white', label='Bitfinex USDC/USDT Mid Price')\n",
    "    ax2.set_ylabel('Price', labelpad=20)\n",
    "    ax2.yaxis.set_label_position(\"left\")\n",
    "    ax2.set_ylim(book_pivot.index[-1], book_pivot.index[0])\n",
    "    ax2.yaxis.tick_left()\n",
    "    ax2.legend(loc='upper left')\n",
    "    \n",
    "    ax2.set_xticks(ax2.get_xticks()[::120])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Orderbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_order_book_heatmap(ask_book,\n",
    "                   bid_book,\n",
    "                   min_price = .85,\n",
    "                   max_price = 1.05,\n",
    "                   startDate = '2023-03-11 0:00:00',\n",
    "                   endDate = '2023-03-11 23:59:00',\n",
    "                   rounding_factor=.001,\n",
    "                   title='USDC/USDT Order Book Heatmap - Bitfinex')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
