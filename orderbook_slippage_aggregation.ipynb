{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions and Description for Amberdata Amazon S3 Bucket Query\n",
    "\n",
    "This Python notebook is designed to perform complex financial analysis on the real-time order book data for the Ethereum-USD trading pair on the Binance exchange using Amberdata's S3 buckets. Below is an overview of the structure and functionalities of the code.\n",
    "\n",
    "### 1. Importing Essential Libraries\n",
    "The code kicks off by importing the necessary Python and PySpark libraries:\n",
    "\n",
    "- `delta.tables`: To work with Delta tables in PySpark.\n",
    "- `pyspark.sql.window`: To apply window functions in Spark SQL.\n",
    "- `pyspark.sql.functions`: To use a wide range of functions in Spark SQL.\n",
    "- `pyspark.sql.types`: To define specific data types.\n",
    "\n",
    "### 2. Data Ingestion and Basic Filtering\n",
    "The code reads data from an S3 bucket containing DeltaLake tables. It applies basic filters to isolate data (feel free to change the filters):\n",
    "\n",
    "- Year: 2023\n",
    "- Month: August\n",
    "- Day: 29\n",
    "- Exchange: Binance\n",
    "- Trading Pair: ETH/USDT\n",
    "\n",
    "### 3. Data Transformation\n",
    "After reading the data, it undergoes several transformations to prepare for analysis:\n",
    "\n",
    "- Type casting: Converting timestamp to `long` data type.\n",
    "- Column selection: Isolating relevant columns like price and quantity.\n",
    "\n",
    "#### Additional Data Filtering:\n",
    "\n",
    "- `bid_book`: Contains the data for bid orders.\n",
    "- `ask_book`: Contains the data for ask orders.\n",
    "\n",
    "### 4. Calculating Slippage and Other Metrics\n",
    "The code calculates slippage, cost, and other metrics based on the real-time order book. The following metrics are computed:\n",
    "\n",
    "- `cum_quantity`: Cumulative sum of quantities.\n",
    "- `cum_cost`: Cumulative sum of cost.\n",
    "- `slippage`: Calculated based on the difference between the desired and actual order amounts.\n",
    "- `currency_slippage`: Slippage in terms of currency.\n",
    "- `dollar_slippage`: Slippage in terms of US dollars.\n",
    "- `percent_slippage`: Slippage as a percentage of the order.\n",
    "\n",
    "### 5. Combining Bid and Ask Books\n",
    "The `bid_book` and `ask_book` are then joined on the `exchangeTimestamp` field, and aggregate metrics are computed.\n",
    "\n",
    "### 6. Resultant Order Book Analysis\n",
    "Finally, the code groups the data by `exchangeTimestamp` to calculate first non-null instances of various slippage metrics for both buying and selling.\n",
    "\n",
    "#### Additional Features:\n",
    "\n",
    "- The code uses the Spark DataFrame's `.cache()` method to cache intermediate DataFrames for improved performance.\n",
    "- Window functions are applied for partitioning and ordering data.\n",
    "\n",
    "### Sample Code Variables\n",
    "You can set your cost basis like this:\n",
    "\n",
    "```python\n",
    "cost_basis = 1_000_000\n",
    "```\n",
    "\n",
    "This sets your cost basis to 1 million USD, and slippage calculations will be based on this.\n",
    "\n",
    "*Note: Due to the real-time nature of the data and heavy calculations, this notebook might take a considerable amount of time to run.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61f6e19d-bc01-40f6-9023-1710c55f5b28",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import StructType, StructField, DataType, BooleanType, NumericType, TimestampType, IntegerType, DecimalType, StringType, LongType, DateType, FloatType\n",
    "from botocore.client import Config\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from itertools import groupby\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from decimal import Decimal\n",
    "from matplotlib.ticker import StrMethodFormatter, PercentFormatter\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02a579cd-ebc1-4bc8-8444-66fb11f2f398",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2. Data Ingestion and Basic Filtering\n",
    "trades = (\n",
    "        DeltaTable\n",
    "        .forPath(spark, 's3://amberdata-marketdata-deltalake/spot/order-book-snapshots/').toDF()\n",
    "        .where('year = \"2023\" \\\n",
    "                AND month = \"08\"\\\n",
    "                AND day = \"29\"\\\n",
    "                AND exchange = \"binance\" \\\n",
    "                AND pair = \"eth_usdt\"')\n",
    "        .select(f.explode('orderBookSides')).select(\"col.exchangeTimestamp\", \"col.isBid\", f.explode('col.data'))\n",
    "         ).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cca905ef-f9ae-4192-b8d1-fe7638697840",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3.1 Data Transformation: Type Casting\n",
    "trades = trades.withColumn('exchangeTimestamp', f.col('exchangeTimestamp').cast('long'))\n",
    "\n",
    "# 3.2 Data Transformation: Column Selection\n",
    "trades = trades\\\n",
    "          .select(f.col(\"col\")\\\n",
    "          .getItem(0).alias(\"price\"), f.col(\"col\")\\\n",
    "          .getItem(1).alias(\"quantity\"), \"*\")\\\n",
    "          .drop(\"col\", 'timestamp_window')\n",
    "\n",
    "# 3.3 Additional Data Filtering: Bid and Ask Books\n",
    "bid_book = trades.filter(f.col(\"isBid\") == True).select(\"*\")\n",
    "ask_book = trades.filter(f.col(\"isBid\") == False).select(\"*\")\n",
    "\n",
    "# 3.4 Renaming Columns\n",
    "bid_book = bid_book.drop(\"isBid\")\n",
    "bid_book = bid_book.withColumnRenamed('price', 'bid_price').withColumnRenamed('quantity', 'bid_quantity')\n",
    "ask_book = ask_book.drop(\"isBid\")\n",
    "ask_book = ask_book.withColumnRenamed('price', 'ask_price').withColumnRenamed('quantity', 'ask_quantity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c4817e2-a3da-4e29-a8b5-94a74ac50618",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 4.1 Preview of Bid and Ask Books\n",
    "ask_book.limit(5).display()\n",
    "bid_book.limit(5).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Window Functions Initialization\n",
    "timestampWindow = Window.partitionBy(\"exchangeTimestamp\")\n",
    "\n",
    "# 5.2 Defining Windows for Bid and Ask Books\n",
    "bid_window = Window.partitionBy('exchangeTimestamp')\\\n",
    "        .orderBy(f.desc('bid_price'))\\\n",
    "        .rowsBetween(Window.unboundedPreceding, 0)\n",
    "\n",
    "ask_window = Window.partitionBy('exchangeTimestamp')\\\n",
    "        .orderBy(f.asc('ask_price'))\\\n",
    "        .rowsBetween(Window.unboundedPreceding, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "597c5461-3efb-4d4a-8d7d-ebbb5db92dae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 6.1 Slippage and Metrics Calculation\n",
    "cost_basis = 1_000_000\n",
    "\n",
    "# 6.2 Calculations for Bid Book\n",
    "bid_book = bid_book\\\n",
    "        .withColumn(\"order_amount\", lit(cost_basis))\\\n",
    "        .withColumn(\"sell_order_price_1\", max(\"bid_price\").over(timestampWindow))\\\n",
    "        .withColumn(\"desired_amount\", col(\"order_amount\") / col(\"sell_order_price_1\"))\\\n",
    "        .withColumn(\"cum_quantity\", sum(\"bid_quantity\").over(bid_window))\\\n",
    "        .withColumn(\"cum_cost\", sum(col(\"bid_quantity\") * col(\"bid_price\")).over(bid_window))\\\n",
    "        .withColumn(\"slippage\", when(col('order_amount') - col('cum_cost') < 0, ((col('order_amount') - (col('cum_cost') - (col('bid_quantity') * col('bid_price')))) / col('bid_price')) + (col('cum_quantity') - col('bid_quantity')))\\\n",
    "            .otherwise(0))\\\n",
    "        .withColumn(\"sell_currency_slippage\", when(col('slippage') != 0, (col(\"desired_amount\") - col(\"slippage\")) *-1 ))\\\n",
    "        .withColumn(\"sell_dollar_slippage\", when(col('slippage') != 0, (col(\"order_amount\") - (col(\"slippage\")*col(\"sell_order_price_1\"))) *-1))\\\n",
    "        .withColumn(\"sell_percent_slippage\", when(col('slippage') != 0, ((col(\"desired_amount\") / col(\"slippage\")) -1 ) *-1 ))\n",
    "\n",
    "# 6.3 Calculations for Ask Book\n",
    "ask_book = ask_book\\\n",
    "        .withColumn(\"order_amount\", lit(cost_basis))\\\n",
    "        .withColumn(\"buy_order_price_1\", min(\"ask_price\").over(timestampWindow))\\\n",
    "        .withColumn(\"desired_amount\", col(\"order_amount\") / col(\"buy_order_price_1\"))\\\n",
    "        .withColumn(\"cum_quantity\", sum(\"ask_quantity\").over(ask_window))\\\n",
    "        .withColumn(\"cum_cost\", sum(col(\"ask_quantity\") * col(\"ask_price\")).over(ask_window))\\\n",
    "        .withColumn(\"slippage\", when(col('order_amount') - col('cum_cost') < 0, ((col('order_amount') - (col('cum_cost') - (col('ask_quantity') * col('ask_price')))) / col('ask_price')) + (col('cum_quantity') - col('ask_quantity')))\\\n",
    "            .otherwise(0))\\\n",
    "        .withColumn(\"buy_currency_slippage\", when(col('slippage') != 0, col(\"desired_amount\") - col(\"slippage\")))\\\n",
    "        .withColumn(\"buy_dollar_slippage\", when(col('slippage') != 0, col(\"order_amount\") - (col(\"slippage\")*col(\"buy_order_price_1\"))))\\\n",
    "        .withColumn(\"buy_percent_slippage\", when(col('slippage') != 0,(col(\"desired_amount\") / col(\"slippage\"))-1))\n",
    "\n",
    "# 6.4 Join and group Bid and Ask Book\n",
    "orderbook = bid_book.join(ask_book, on='exchangeTimestamp', how='inner')\n",
    "\n",
    "orderbook = orderbook.groupby(\"exchangeTimestamp\")\\\n",
    "            .agg(first(col(\"buy_currency_slippage\"), ignorenulls=True).alias(\"buy_currency_slippage\"),\n",
    "                 first(col(\"buy_dollar_slippage\"), ignorenulls=True).alias(\"buy_dollar_slippage\"),\n",
    "                 first(col(\"buy_percent_slippage\"), ignorenulls=True).alias(\"buy_percent_slippage\"),\n",
    "                 first(col(\"sell_currency_slippage\"), ignorenulls=True).alias(\"sell_currency_slippage\"),\n",
    "                 first(col(\"sell_dollar_slippage\"), ignorenulls=True).alias(\"sell_dollar_slippage\"),\n",
    "                 first(col(\"sell_percent_slippage\"), ignorenulls=True).alias(\"sell_percent_slippage\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0b22328-867e-4df7-9c09-f8ff87b1181f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 7. Display Results\n",
    "orderbook.limit(5).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_heatmap(df, column, title, color_palette, dpi=75):\n",
    "    df['hour_of_day'] = df.index.hour\n",
    "    df['day_of_week'] = df.index.dayofweek\n",
    "    days = ['Mon.', 'Tue.', 'Wed.', 'Thu.', 'Fri.', 'Sat.', 'Sun.']\n",
    "    df['day_of_week'] = df['day_of_week'].apply(lambda x: days[x])\n",
    "    pivot = df.pivot_table(index='day_of_week', columns='hour_of_day', values=column, aggfunc='mean')\n",
    "    pivot = pivot.reindex(['Sun.','Mon.', 'Tue.', 'Wed.', 'Thu.', 'Fri.', 'Sat.'])\n",
    "\n",
    "    # Create the heatmap\n",
    "    sns.heatmap(pivot, annot=False, fmt='.2f', cmap = sns.color_palette(color_palette, as_cmap=True))\n",
    "    # Add x and y labels\n",
    "    plt.xlabel('Hour (UTC)')\n",
    "    plt.ylabel('Day')\n",
    "    plt.title(title, loc='left')\n",
    "    plt.gcf().set_dpi(dpi)\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    \n",
    "def plot_regression(x, y, xlabel, ylabel, title, color, size, alpha):\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    sns.regplot(x=x, y=y, color=color, scatter_kws={'s':size, 'alpha':alpha})\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n",
    "\n",
    "def plot_slippage(slippage, title):\n",
    "    plt.figure(figsize=(15,7), dpi=100)\n",
    "    ax = plt.gca()\n",
    "\n",
    "    low_color = 'green'\n",
    "    high_color = 'red'\n",
    "\n",
    "    low_quantile = slippage.quantile(.25)\n",
    "    high_quantile = slippage.quantile(.75)\n",
    "\n",
    "    plt.fill_between(merged_df.index, merged_df['Close'], 0, \n",
    "                     where=(slippage <= low_quantile),\n",
    "                     facecolor=low_color, alpha = .5)\n",
    "\n",
    "    plt.fill_between(merged_df.index, merged_df['Close'], 0, \n",
    "                     where=(slippage >= high_quantile),\n",
    "                     facecolor=high_color, alpha = .5)\n",
    "    \n",
    "    plt.plot(merged_df.index, merged_df['Close'], color='black', linewidth=1)\n",
    "\n",
    "    ax.set_ylim(merged_df['Close'].min()*.975, merged_df['Close'].max()*1.025)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.ylabel('ETH/USDT 1h Close Price')\n",
    "\n",
    "    low_legend = mpatches.Patch(color=low_color, label= '≤ 25th Percentile')\n",
    "    high_legend = mpatches.Patch(color=high_color, label= '≥ 75th Percentile')\n",
    "    plt.legend(handles=[low_legend, high_legend])\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def plot_slippage_hv(slippage, title):\n",
    "    plt.figure(figsize=(15,7), dpi=100)\n",
    "    ax = plt.gca()\n",
    "\n",
    "    low_color = 'green'\n",
    "    high_color = 'red'\n",
    "\n",
    "    low_quantile = slippage.quantile(.25)\n",
    "    high_quantile = slippage.quantile(.75)\n",
    "\n",
    "    plt.fill_between(merged_df.index, merged_df['hv'], 0, \n",
    "                     where=(slippage <= low_quantile),\n",
    "                     facecolor=low_color, alpha = .5)\n",
    "\n",
    "    plt.fill_between(merged_df.index, merged_df['hv'], 0, \n",
    "                     where=(slippage >= high_quantile),\n",
    "                     facecolor=high_color, alpha = .5)\n",
    "    \n",
    "    plt.plot(merged_df.index, merged_df['hv'], color='black', linewidth=1)\n",
    "\n",
    "    ax.set_ylim(merged_df['hv'].min()*.975, merged_df['hv'].max()*1.025)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.ylabel('ETH/USDT 24h Hist. Volatility (C/C)')\n",
    "\n",
    "    low_legend = mpatches.Patch(color=low_color, label= '≤ 25th Percentile')\n",
    "    high_legend = mpatches.Patch(color=high_color, label= '≥ 75th Percentile')\n",
    "    plt.legend(handles=[low_legend, high_legend])\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def plot_slippage_iv(slippage, title):\n",
    "    plt.figure(figsize=(15,7), dpi=100)\n",
    "    ax = plt.gca()\n",
    "\n",
    "    low_color = 'green'\n",
    "    high_color = 'red'\n",
    "\n",
    "    low_quantile = slippage.quantile(.25)\n",
    "    high_quantile = slippage.quantile(.75)\n",
    "\n",
    "    plt.fill_between(merged_df.index, merged_df['atm7'], 0, \n",
    "                     where=(slippage <= low_quantile),\n",
    "                     facecolor=low_color, alpha = .5)\n",
    "\n",
    "    plt.fill_between(merged_df.index, merged_df['atm7'], 0, \n",
    "                     where=(slippage >= high_quantile),\n",
    "                     facecolor=high_color, alpha = .5)\n",
    "    \n",
    "    plt.plot(merged_df.index, merged_df['atm7'], color='black', linewidth=1)\n",
    "\n",
    "    ax.set_ylim(merged_df['atm7'].min()*.975, merged_df['atm7'].max()*1.025)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.ylabel('ETH ATM7 Implied Volatility')\n",
    "\n",
    "    low_legend = mpatches.Patch(color=low_color, label= '≤ 25th Percentile')\n",
    "    high_legend = mpatches.Patch(color=high_color, label= '≥ 75th Percentile')\n",
    "    plt.legend(handles=[low_legend, high_legend])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderbook['slippage_median'] = orderbook['sell_percent_slippage'].rolling(60*24).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the column 'buy/sell_dollar_slippage' against its index\n",
    "plt.plot(orderbook.index, orderbook['slippage_median'], linewidth = 0.5, color = 'black', label='Sell Slippage')\n",
    "# Adding labels to the x and y axes\n",
    "plt.ylabel('Percent Slippage(%)')\n",
    "plt.title(\"Intra-day Binance ETH/USDT $1m Sell Slipage Rolling Median\")\n",
    "\n",
    "# Rotate the x-axis labels by 45 degrees to prevent overlap\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Set the x-axis major tick format to display hours\n",
    "plt.gcf().axes[0].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M'))\n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "plt.gcf().set_dpi(150)\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_orderbook = orderbook.resample('4H').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the column 'buy/sell_dollar_slippage' against its index\n",
    "plt.plot(resampled_orderbook.index, resampled_orderbook['buy_percent_slippage'], linewidth = 0.2, color = 'red', label='Buy Slippage')\n",
    "plt.plot(resampled_orderbook.index, resampled_orderbook['sell_percent_slippage'], linewidth = 0.2, color = 'green', label='Sell Slippage')\n",
    "# Adding labels to the x and y axes\n",
    "plt.ylabel('Percent Slippage(%)')\n",
    "plt.title(\"Intra-day Binance ETH/USDT $1m Buy & Sell Order Slippage\")\n",
    "\n",
    "# Rotate the x-axis labels by 45 degrees to prevent overlap\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Set the x-axis major tick format to display hours\n",
    "plt.gcf().axes[0].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M'))\n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "plt.gcf().set_dpi(150)\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderbook['Slippage Difference'] = orderbook['sell_percent_slippage'] - orderbook['buy_percent_slippage']\n",
    "# Plotting the column 'buy/sell_dollar_slippage' against its index\n",
    "plt.plot(orderbook.index, orderbook['Slippage Difference'], linewidth = 0.5, color = 'black')\n",
    "\n",
    "# Adding a faint grey dotted line at the 0 y axis mark\n",
    "plt.axhline(y=0, linewidth = 0.5, color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Adding labels to the x and y axes\n",
    "plt.ylabel('Slippage Difference(%)')\n",
    "plt.title(\"Intra-day Binance ETH/USDT $1m Sell-to-Buy Slippage Difference\")\n",
    "\n",
    "# Rotate the x-axis labels by 45 degrees to prevent overlap\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Set the x-axis major tick format to display hours\n",
    "plt.gcf().axes[0].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M'))\n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "plt.gcf().set_dpi(150)\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_heatmap(orderbook, 'sell_percent_slippage', '$1,000,000 ETH/USDT Sell Order Slippage % Heatmap', 'Reds')\n",
    "create_heatmap(orderbook, 'buy_percent_slippage', '$1,000,000 ETH/USDT Buy Order Slippage % Heatmap', 'Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_Key = \"INSERT_YOUR_API_KEY_HERER\"\n",
    "\n",
    "def get_data(start_date, end_date, headers):\n",
    "    url = f\"https://web3api.io/api/v2/market/spot/ohlcv/eth_usd/historical?exchange=bitstamp&startDate={start_date}&endDate={end_date}&timeInterval=hours\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = json.loads(response.text)\n",
    "    ohlc = pd.DataFrame(data['payload']['data']['bitstamp'], columns=data['payload']['metadata']['columns'])\n",
    "    ohlc['timestamp'] = pd.to_datetime(ohlc['timestamp'], unit='ms')\n",
    "    ohlc.set_index('timestamp', inplace=True)\n",
    "    ohlc.columns = [col.title() for col in ohlc.columns]\n",
    "    return ohlc\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"x-api-key\": API_Key\n",
    "}\n",
    "\n",
    "ohlc1 = get_data(\"2022-01-01T00%3A00%3A00\", \"2022-02-01T00%3A00%3A00\", headers)\n",
    "ohlc2 = get_data(\"2022-02-01T00%3A00%3A00\", \"2022-03-01T00%3A00%3A00\", headers)\n",
    "ohlc3 = get_data(\"2022-03-01T00%3A00%3A00\", \"2022-04-01T00%3A00%3A00\", headers)\n",
    "ohlc4 = get_data(\"2022-04-01T00%3A00%3A00\", \"2022-05-01T00%3A00%3A00\", headers)\n",
    "ohlc5 = get_data(\"2022-05-01T00%3A00%3A00\", \"2022-06-01T00%3A00%3A00\", headers)\n",
    "ohlc6 = get_data(\"2022-06-01T00%3A00%3A00\", \"2022-07-01T00%3A00%3A00\", headers)\n",
    "ohlc7 = get_data(\"2022-07-01T00%3A00%3A00\", \"2022-08-01T00%3A00%3A00\", headers)\n",
    "ohlc8 = get_data(\"2022-08-01T00%3A00%3A00\", \"2022-09-01T00%3A00%3A00\", headers)\n",
    "ohlc9 = get_data(\"2022-09-01T00%3A00%3A00\", \"2022-10-01T00%3A00%3A00\", headers)\n",
    "ohlc10 = get_data(\"2022-10-01T00%3A00%3A00\", \"2022-11-01T00%3A00%3A00\", headers)\n",
    "ohlc11 = get_data(\"2022-11-01T00%3A00%3A00\", \"2022-12-01T00%3A00%3A00\", headers)\n",
    "ohlc12 = get_data(\"2022-12-01T00%3A00%3A00\", \"2023-01-01T00%3A00%3A00\", headers)\n",
    "ohlc13 = get_data(\"2023-01-01T00%3A00%3A00\", \"2023-02-01T00%3A00%3A00\", headers)\n",
    "ohlc14 = get_data(\"2023-02-01T00%3A00%3A00\", \"2023-03-01T00%3A00%3A00\", headers)\n",
    "\n",
    "df = pd.concat([ohlc1, ohlc2, ohlc3, ohlc4, ohlc5, ohlc6, ohlc7, ohlc8, ohlc9, ohlc10, ohlc11, ohlc12, ohlc13, ohlc14], axis=0, join='inner', ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parksinson_volatility(prices, window=24, trading_periods=365, clean=True):\n",
    "\n",
    "    rs = (1.0 / (4.0 * math.log(2.0))) * ((prices['High'] / prices['Low']).apply(np.log))**2.0\n",
    "\n",
    "    def f(v):\n",
    "        return (trading_periods * v.mean())**0.5\n",
    "    \n",
    "    result = rs.rolling(\n",
    "        window=window,\n",
    "        center=False\n",
    "    ).apply(func=f)\n",
    "    \n",
    "    if clean:\n",
    "        return result.dropna()\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "df['hv'] = parksinson_volatility(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the column 'buy/sell_dollar_slippage' against its index\n",
    "plt.plot(df.index, df['hv'], linewidth = 0.5, color = 'black', label='Sell Slippage')\n",
    "# Adding labels to the x and y axes\n",
    "plt.ylabel('Realized Volatility')\n",
    "plt.title(\"Bitstamp ETH/USDT 24h Realized Vol (Parkinson)\")\n",
    "\n",
    "# Rotate the x-axis labels by 45 degrees to prevent overlap\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Set the x-axis major tick format to display hours\n",
    "plt.gcf().axes[0].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M'))\n",
    "plt.gcf().set_dpi(100)\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the column 'buy/sell_dollar_slippage' against its index\n",
    "plt.plot(df.index, df['Volume'], linewidth = 0.5, color = 'black', label='Sell Slippage')\n",
    "# Adding labels to the x and y axes\n",
    "plt.ylabel('Realized Volatility')\n",
    "plt.title(\"Intra-day Bitstamp 1hr ETH/USDT Volume\")\n",
    "\n",
    "# Rotate the x-axis labels by 45 degrees to prevent overlap\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Set the x-axis major tick format to display hours\n",
    "plt.gcf().axes[0].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M'))\n",
    "plt.gcf().set_dpi(100)\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderbook = orderbook.resample('H').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = df.merge(orderbook, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://app.pinkswantrading.com/graphql\"\n",
    "headers = {\n",
    "          'x-oracle': str(API_Key),\n",
    "          'Content-Type': 'application/json',\n",
    "          'accept': '*/*',\n",
    "          'Accept-Language': 'en-US,en;q=0.9'\n",
    "        }\n",
    "\n",
    "payload=\"{\\\"query\\\":\\\"query ConstantMaturityAtm1Min($symbol: BTCOrETHEnumType, $dateStart: String, $dateEnd: String, $interval: String){\\\\n  ConstantMaturityAtm1Min(symbol:$symbol, dateStart:$dateStart, dateEnd: $dateEnd, interval: $interval) {\\\\n    date\\\\n    atm7\\\\n    atm30\\\\n    atm60\\\\n    atm90\\\\n    atm180\\\\n  }\\\\n}\\\\n\\\",\\\"variables\\\":{\\\"symbol\\\":\\\"ETH\\\",\\\"dateStart\\\":\\\"2022-01-01\\\",\\\"dateEnd\\\":\\\"2023-02-08\\\",\\\"interval\\\":\\\"(1 hour)\\\"}}\"\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "\n",
    "iv = response.json()\n",
    "iv = pd.DataFrame(iv['data']['ConstantMaturityAtm1Min'])\n",
    "iv['timestamp'] = pd.to_datetime(iv['date'], unit='ms')\n",
    "iv = iv.sort_values(by='timestamp', ascending=True)\n",
    "iv = iv.set_index('timestamp')\n",
    "iv = iv.drop(['date'], axis = 1)\n",
    "iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.merge(iv, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_heatmap(merged_df, 'atm7', 'Deribit ETH/USD ATM7 Implied Volatility Heatmap', 'Oranges')\n",
    "create_heatmap(merged_df, 'hv', 'Bitstamp ETH/USDT Realized Volatility Heatmap', 'Blues')\n",
    "create_heatmap(merged_df, 'Volume', 'Bitstamp ETH/USDT Volume Heatmap', 'Purples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = merged_df['buy_percent_slippage'].corr(merged_df['hv'])\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = merged_df['Volume']\n",
    "y = merged_df['sell_percent_slippage']\n",
    "xlabel = \"Volume\"\n",
    "ylabel = \"$1m Sell Order Slippage\"\n",
    "title = \"Regression Plot between $1m Sell Order Slippage (%) and Volume\"\n",
    "color = 'black'\n",
    "size = 2.5\n",
    "alpha = 1\n",
    "\n",
    "plot_regression(x, y, xlabel, ylabel, title, color, size, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = merged_df['Volume']\n",
    "y = merged_df['buy_percent_slippage']\n",
    "xlabel = \"Volume\"\n",
    "ylabel = \"$1m Buy Order Slippage\"\n",
    "title = \"Regression Plot between $1m Buy Order Slippage (%) and Volume\"\n",
    "color = 'black'\n",
    "size = 2.5\n",
    "alpha = 1\n",
    "\n",
    "plot_regression(x, y, xlabel, ylabel, title, color, size, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = merged_df['atm7']\n",
    "y = merged_df['buy_percent_slippage']\n",
    "xlabel = \"ATM7 Implied Volatility\"\n",
    "ylabel = \"$1m Buy Order Slippage\"\n",
    "title = \"Regression Plot between $1m Buy Order Slippage (%) and ATM7 Implied Volatility\"\n",
    "color = 'black'\n",
    "size = 2.5\n",
    "alpha = 1\n",
    "\n",
    "plot_regression(x, y, xlabel, ylabel, title, color, size, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function for buy slippage\n",
    "slippage_buy = merged_df['buy_percent_slippage']\n",
    "plot_slippage(slippage_buy, 'ETH/USDT 1hr Close Price vs. $1m Buy Order Slippage')\n",
    "\n",
    "# Call the function for sell slippage\n",
    "slippage_sell = merged_df['sell_percent_slippage']\n",
    "plot_slippage(slippage_sell, 'ETH/USDT 1hr Close Price vs. $1m Sell Order Slippage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function for buy slippage\n",
    "slippage_buy = merged_df['hv']\n",
    "plot_slippage(slippage_buy, 'ETH/USDT 1hr Close Price vs. Hist. Volatility (C/C)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function for buy slippage\n",
    "slippage_buy = merged_df['atm30']\n",
    "plot_slippage(slippage_buy, 'ETH/USDT 1hr Close Price vs. ATM 30 Implied Volatility')\n",
    "\n",
    "# Call the function for sell slippage\n",
    "slippage_sell = merged_df['atm30']\n",
    "plot_slippage(slippage_sell, 'ETH/USDT 1hr Close Price vs. ATM 30 Implied Volatility')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function for buy slippage\n",
    "slippage_buy = merged_df['buy_percent_slippage']\n",
    "plot_slippage_hv(slippage_buy, 'ETH/USDT 24hr Hist. Volatility (Parksinson) vs. $1m Buy Order Slippage')\n",
    "\n",
    "# Call the function for sell slippage\n",
    "slippage_sell = merged_df['sell_percent_slippage']\n",
    "plot_slippage_hv(slippage_sell, 'ETH/USDT 24hr Hist. Volatility (Parksinson) vs. $1m Sell Order Slippage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function for buy slippage\n",
    "slippage_buy = merged_df['buy_percent_slippage']\n",
    "plot_slippage_iv(slippage_buy, 'ETH ATM7 Implied Volatility vs. $1m Buy Order Slippage')\n",
    "\n",
    "# Call the function for sell slippage\n",
    "slippage_sell = merged_df['sell_percent_slippage']\n",
    "plot_slippage_iv(slippage_sell, 'ETH ATM7 Implied Volatility vs. $1m Sell Order Slippage')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Historical Orderbook Bid Ask Spread Aggregation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
